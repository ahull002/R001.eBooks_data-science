{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Shortcuts!\n",
    "Information Aggregated by Alfred Hull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "__What is pandas?__ pandas is the most popular python library that is used for data analysis. It provides highly optimized performance with back-end source code is purely written in C or Python. It suppots: cvs, sql, json, html, etc.\n",
    "\n",
    "Data Structure: \n",
    "- Pandas supports up to two-dimentions DataFrame\n",
    "- 1D objects are called Series. \n",
    "- 2D objects are called DataFrame. \n",
    "- The structure is Rows and Columns. \n",
    "\n",
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html\">Click Here To Access: pandas documentation </a>\n",
    "\n",
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\">Click Here To Access: pandas transormation documentation </a> \n",
    "\n",
    "__What is NumPy?__\n",
    "NumPy is a general-purpose array-processing package. It provides a high-performance multidimensional array object, and tools for working with these arrays.\n",
    "\n",
    "It is the fundamental package for scientific computing with Python. It contains various features including these important ones:\n",
    "\n",
    "* A powerful N-dimensional array object\n",
    "* Sophisticated (broadcasting) functions\n",
    "* Tools for integrating C/C++ and Fortran code\n",
    "* Useful linear algebra, Fourier transform, and random number capabilities\n",
    "\n",
    "Besides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined using Numpy which allows NumPy to seamlessly and speedily integrate with a wide variety of databases.\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/\">Click Here To Access: NumPy documentation </a>\n",
    "\n",
    "\n",
    "__What is Beautiful Soup?__\n",
    "Beautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "<a href=\"https://pypi.org/project/beautifulsoup4/\">Click Here To Access: Beautiful Soup documentation </a>\n",
    "\n",
    "***\n",
    "__References:__\n",
    "\n",
    "Follow me: <a href=\"https://www.linkedin.com/in/alfredhull/\">Go To Me @LinkedIn </a>\n",
    "\n",
    "1. https://www.geeksforgeeks.org/numpy-in-python-set-1-introduction/\n",
    "2. https://www.datacamp.com/courses/pandas-foundations\n",
    "3. https://sinxloud.com/python-cheat-sheet-beginner-advanced/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file.csv') \n",
    "df = pd.read_csv('file.csv', index_col=0)\n",
    "\n",
    "#needs beautifulsoup (referenced above) for manipulation\n",
    "#options but not unique\n",
    "df = pd.read_html(url) \n",
    "df = pd.read_json()\n",
    "df = pd.read_sql()\n",
    "df = pd.read_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will save the file as dataframe without an index\n",
    "df.to_csv('file_name.csv',index=False)\n",
    "\n",
    "#to file options\n",
    "df.to_json()\n",
    "df.to_sql()\n",
    "pd.to_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime\n",
    "pd.to_timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Data Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #Returns the columns \n",
    "df.dtypes #Returns the datatypes\n",
    "df.index #Retuns the idex\n",
    "df.shape #Returnsthe shape\n",
    "df.T #Returns the dataframe inverted \n",
    "df.values #Returns the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Transformation: Join, Merge and Concat\n",
    "Common adjustments: \n",
    "\n",
    "- `ignore_index = True`-  When the index is not relevant for the join\n",
    "- `axis= 0`: adds up rows | `axis= 1` Adds up the columns\n",
    "- `keys = ['a', 'b', 'c']`-  Adds up the DataFrame on certain keys\n",
    "- `left` join - Use keys from left frame only\n",
    "- `right` join - Use keys from right frame only\n",
    "- `outer` - Use union of keys from both frames\n",
    "- `inner` - Use intersection of keys from both frames\n",
    "\n",
    "_In some cases, if we want to modify the existing DataFrame we are working `inplace=True` needs to be appled._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This joins dataframes based on the Index (It is important that the DataFrames being merged have the same index) \n",
    "\n",
    "df_1.join(df_2) \n",
    "\n",
    "pd.concat([df_1, df_2], axis=1, join='outer', ignore_index=False, keys=None,\n",
    "          levels=None, names=None, verify_integrity=False, copy=True) #the values can be changed as needed\n",
    "\n",
    "df_1.pd.append(df_2, sort = True, inplace = True) #This will add dataframes with the same column structure and names\n",
    "\n",
    "dataframes = {'a': df_1, 'b': df_2, 'c': df_3}\n",
    "new_df  = pd.concat(dataframes) #this will concat the dataframes indicated in the dataframes dictionary and create a new colum indicating the origin of the data\n",
    "\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns Addition and Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum_col1_col2'] = df['col_1'] + df['col_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Use this if you want to see the values of certain columns or rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #Returns the first 5 values\n",
    "\n",
    "df.tail() #Returns the last 5 values\n",
    "\n",
    "df['column_name'] #Returns all the data in the column\n",
    "df.column_name #Returns all the data in the column\n",
    "df['column_name', 'second_column'] #Returns columns as a new DataFrame\n",
    "df[7:9] # Displays the values of rows 7 to 9\n",
    "df.value_counts(dropna=False)  #Retuns unique values and counts\n",
    "df.sort_index(axis=0, ascending=False) #Returns dataframe sorted by index\n",
    "df.apply(pd.Series.value_counts) #Returns values and counts for all columns\n",
    "df.sort_values(by='column_name') #Returns dataframe sorted by the column selected\n",
    "df.groupby('column_name').mean() #Returns dataframe grouped by column name and the mean\n",
    "df.pivot_table\n",
    "df.iloc[0] #Selection by position\n",
    "df.loc['index_one'] # Selection by index\n",
    "df.iloc[0,:]  #Returns First row\n",
    "df.iloc[0,0] #Returns element of first column\n",
    "\n",
    "#Simple examples that can be adapted as needed\n",
    "\n",
    "df[df['is_muy_value'] == 1][['what_im_looking_for']]\n",
    "\n",
    "df[df['column_1'] < 10].groupby('column_2').mean()[['what_im_looking_for']]\n",
    "df[df['column_1'] == 0].sort_values(by='column_2', ascending=False).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing and renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['column_1', 'column_2'] #Renames columns\n",
    "df.rename(columns={'old_name': 'new_ name'}) # Selective renaming\n",
    "\n",
    "df.replace(1,'one') #Replace all values equal to 1 with ‘one’\n",
    "df.replace([1,3],['one','three']) #Replace all 1 with ‘one’ and 3 with ‘three’\n",
    "\n",
    "\n",
    "df.set_index('column_1') #Changes the index\n",
    "df.astype(int) # Converts the datatype of the series to integer - It can be changed to any datatype\n",
    "\n",
    "df['column_1'].astype(int) #changes the datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values\n",
    "- `isna` = `isnull`\n",
    "- `notna` = `notnull`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(value = 'my_selected_value', inplace = True) # fills all NANs with the value we selected and make the change permanent\n",
    "df.fillna(x) # Replace all null values with x\n",
    "df.notna().sum() #Sum of nas per column\n",
    "df.interpolate()\n",
    "df.isna().sum() #Return True/false to NAs\n",
    "df.isnull()\n",
    "df.dropna(inplace = True) # Drops null values permanently\n",
    "df.isnull().sum() #Prints null values agregated by column\n",
    "df.isnull().sum()[df.isnull().sum() !=0].sort_values().plot(kind='barh'); #Plots the null values\n",
    "\n",
    "#Advance replacing:\n",
    "df.fillna(df.mean()) #Replace all null values with the mean \n",
    "\n",
    "#Other way to overwrite the dataframe without the NAs in specific column\n",
    "df.column.fillna(value='no_info', inplace=True) \n",
    "df= df.loc[df['column'] != 'no_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['column_1', 'column_2'], axis=1, inplace = True) #drops specific columns\n",
    "df.drop_duplicates(inplace=True) #drops duplicates permanently\n",
    "df.drop('row_1', axis=0, inplace = True) #drops the row permanently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregation Methods, statistical methods and summaries\n",
    "Can be used in way `df.sum` and `df.sum()` way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count() # Returns the number of non-null values in each DataFrame column\n",
    "df.describe() # Summary statistics for numerical columns\n",
    "df.max() #Returns the highest value in each column\n",
    "df.mean() #Returns the mean of all columns\n",
    "df.median() # Returns the median of each column\n",
    "df.min() # Returns the lowest value in each column\n",
    "df.mode() #Returns mode \n",
    "df.std() # Returns the standard deviation of each column\n",
    "df.var() #retuns varianza\n",
    "df.abs() #Returns absolute values\n",
    "df.corr() # Returns the correlation between columns in a DataFrame\n",
    "df.round() #rounds the number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clip()\n",
    "df.nunique() \n",
    "df.idxmax()\n",
    "df.idxmin()\n",
    "df.cov()\n",
    "df.cummax()\n",
    "df.cummin()\n",
    "df.cumprod()\n",
    "df.cumsum()\n",
    "df.diff()\n",
    "df.nlargest()\n",
    "df.nsmallest()\n",
    "df.pct_change()\n",
    "df.prod()\n",
    "df.quantile()\n",
    "df.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Variables\n",
    "\n",
    "__What are Dummy Variables?__ A dummy variable is a numerical variable used in regression analysis to represent subgroups of the sample in your study. In research design, a dummy variable is often used to distinguish different treatment groups. In the simplest case, we would use a 0,1 dummy variable where a person is given a value of 0 if they are in the control group or a 1 if they are in the treated group. Dummy variables are useful because they enable us to use a single regression equation to represent multiple groups. This means that we don't need to write out separate equation models for each subgroup. The dummy variables act like 'switches' that turn various parameters on and off in an equation. Another advantage of a 0,1 dummy-coded variable is that even though it is a nominal-level variable you can treat it statistically like an interval-level variable (if this made no sense to you, you probably should refresh your memory on levels of measurement). For instance, if you take an average of a 0,1 variable, the result is the proportion of 1s in the distribution.\n",
    "\n",
    "<a href=\"https://socialresearchmethods.net/kb/dummyvar.php\">Click Here To Access: social research methods </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['my_column'], drop_first=True) #I dummy variables we drop the first column to not to make it redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple data exploration\n",
    "def df_EDA(df):\n",
    "    print('SHAPE:', df.shape)\n",
    "    print('----------------')\n",
    "    print('SUM OF NULL VALUES:', df.isnull().sum())\n",
    "    print('----------------')\n",
    "    print('DATA TYPES:')\n",
    "    print(df.dtypes)\n",
    "    print('----------------')\n",
    "    print('DESCRIPTIVE STATISTICS:')\n",
    "    return df.describe().T\n",
    "\n",
    "df_EDA(your_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does this colum has the value I'm looking for?\n",
    "def is_the_value_im_looking(i):\n",
    "    val = i.split()\n",
    "    if 'value' in str(val):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#Create a column called as the value I'm looking for and adds 0 or one\n",
    "df['value'] = df['col_1'].apply(is_the_value_im_looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract certaiun the title from everyone's name and create dummy columns, made with list comprehension.\n",
    "#This can be adapted as needed\n",
    "\n",
    "df['Title'] = [each.split(',')[1].split('.')[0].strip() for each in df['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rate per column. \n",
    "#this can be adapted as needed. \n",
    "\n",
    "for i in ['column_1', 'column_2', 'column_3']:\n",
    "    print(i, ':')\n",
    "    print(df[df[i] == 1][['the_value_im_lookingfor']].mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "Simple ploting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('column_1').mean()[['value']].plot(kind='barh')\n",
    "plt.title(\"plot title\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['column_1', 'colum_2']).mean()[['value']].plot(kind='barh');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
